{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m_SP0x1jyRt"
   },
   "source": [
    "## Import Modules for Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of all image processing relevant library imports:\n",
    "\n",
    "    pip install torchmetrics -q\n",
    "\n",
    "import pandas as pd import numpy as np import os import re import copy import time from PIL import Image import seaborn as sns import matplotlib.pyplot as plt from collections.\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader from torchvision import transforms from PIL import Image import torch import torch.nn as nn from torchvision import models from transformers, from torchmetrics.classification import MulticlassF1Score import torch.nn.functional as F\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, array_to_img import warnings %matplotlib inline warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchmetrics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, array_to_img\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(torch.cuda.current_device()) if torch.cuda.is_available() else print(\"CUDA is not available. Using CPU.\")\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wi2o7xUj5Tk"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q \"/your-path/images.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image path to access images\n",
    "train['image_path'] = train.apply(lambda x: f\"images/image_train/image_{x['imageid']}_product_{x['productid']}.jpg\", axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skosE1ELnoCL",
    "outputId": "e0507552-4808-46a0-8281-33a99aff845f"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_o-2j032np7c",
    "outputId": "36e76765-4eb1-4d3d-f240-697b0699bb35"
   },
   "outputs": [],
   "source": [
    "train['prdtypecode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v00O5FOSnx87",
    "outputId": "ccf6da28-a298-4a33-b60c-5c96f3f62000"
   },
   "outputs": [],
   "source": [
    "# total output classes in the dataset\n",
    "train['prdtypecode'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnOUf5a0klTB"
   },
   "source": [
    "## Data Preprocessing for Image-Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTLduQRHo5op"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['prdtypecode'] = le.fit_transform(train['prdtypecode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0C0H2GY0mVA3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42, stratify=train['prdtypecode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnKaBGtwmU_W"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j78XNOhtmU9f"
   },
   "outputs": [],
   "source": [
    "class RakutenDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, max_text_length=50):\n",
    "        self.image_paths = df['image_path']\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        text = self.text_data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load and transform the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "\n",
    "        # One-hot encode the label\n",
    "        # label_one_hot = F.one_hot(torch.tensor(label), num_classes=self.num_classes)\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'text_tokens': text_tokens,\n",
    "            'label': torch.tensor(label)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfFOtYeXsr3k"
   },
   "outputs": [],
   "source": [
    "# Define transformations for training images\n",
    "image_transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0), ratio=(0.8, 1.2)),  # Resize to 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Adjust color jitter\n",
    "    transforms.RandomRotation(degrees=15),  # Randomly rotate the image by up to 15 degrees\n",
    "    transforms.RandomVerticalFlip(),  # Randomly flip the image vertically\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=0.1),  # Random affine transformations\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
    "])\n",
    "\n",
    "# Define transformations for validation images\n",
    "image_transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(), # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1I-p5I8sr0g"
   },
   "outputs": [],
   "source": [
    "# Create an instance of the dataset\n",
    "train_dataset = RakutenDataset(train_df, transform=image_transform_train)\n",
    "val_dataset = RakutenDataset(val_df, transform=image_transform_val)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
